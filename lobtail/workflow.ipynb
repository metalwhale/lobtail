{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [`workflow_by_code.ipynb`](https://github.com/microsoft/qlib/blob/v0.9.2/examples/workflow_by_code.ipynb)\n",
    "- [Converting CSV Format into Qlib Format](https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "CSV_PATH = pathlib.Path.home() / \".qlib\" / \"csv_data\" / \"bitfinex_data\"\n",
    "PROVIDER_URI = pathlib.Path.home() / \".qlib\" / \"qlib_data\" / \"bitfinex_data\"\n",
    "\n",
    "shutil.rmtree(CSV_PATH)\n",
    "shutil.rmtree(PROVIDER_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from time import strftime, localtime\n",
    "\n",
    "\n",
    "def fetch_bitfinex_candles(csv_path: pathlib.PosixPath, pair: str = \"BTCUSD\", limit: int = 10000):\n",
    "    os.makedirs(CSV_PATH, exist_ok=True)\n",
    "    # See: https://docs.bitfinex.com/reference/rest-public-candles\n",
    "    url = f\"https://api-pub.bitfinex.com/v2/candles/trade:1D:t{pair}/hist?limit={limit}\"\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    with open(csv_path / f\"{pair}.csv\", \"w\") as candles_file:\n",
    "        candles_writer = csv.writer(candles_file)\n",
    "        candles_writer.writerow([\"MTS\", \"OPEN\", \"CLOSE\", \"HIGH\", \"LOW\", \"VOLUME\", \"IS_MISSING\"])\n",
    "        candles = list(response.json())\n",
    "        candles.reverse()  # Ascending order\n",
    "        last_candle = None\n",
    "        for candle in candles:\n",
    "            MILLISECONDS_IN_DAY = 24 * 60 * 60 * 1000\n",
    "            if last_candle is not None:\n",
    "                for t in range(last_candle[0] + MILLISECONDS_IN_DAY, candle[0], MILLISECONDS_IN_DAY):\n",
    "                    candles_writer.writerow([strftime(\"%Y-%m-%d\", localtime(t // 1000)), *last_candle[1:], True])\n",
    "            candles_writer.writerow([strftime(\"%Y-%m-%d\", localtime(candle[0] // 1000)), *candle[1:], False])\n",
    "            last_candle = candle\n",
    "\n",
    "\n",
    "fetch_bitfinex_candles(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-05 14:34:58.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_all_date\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1mstart get all date......\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 13.06it/s]\n",
      "\u001b[32m2023-07-05 14:34:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_all_date\u001b[0m:\u001b[36m294\u001b[0m - \u001b[1mend of get all date.\n",
      "\u001b[0m\n",
      "\u001b[32m2023-07-05 14:34:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_dump_calendars\u001b[0m:\u001b[36m297\u001b[0m - \u001b[1mstart dump calendars......\u001b[0m\n",
      "\u001b[32m2023-07-05 14:34:58.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_dump_calendars\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mend of calendars dump.\n",
      "\u001b[0m\n",
      "\u001b[32m2023-07-05 14:34:58.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_dump_instruments\u001b[0m:\u001b[36m303\u001b[0m - \u001b[1mstart dump instruments......\u001b[0m\n",
      "\u001b[32m2023-07-05 14:34:58.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_dump_instruments\u001b[0m:\u001b[36m305\u001b[0m - \u001b[1mend of instruments dump.\n",
      "\u001b[0m\n",
      "\u001b[32m2023-07-05 14:34:58.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_dump_features\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mstart dump features......\u001b[0m\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/usr/src/qlib/scripts/dump_bin.py:198: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  calendars_df[self.date_field_name] = calendars_df[self.date_field_name].astype(np.datetime64)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.30it/s]\n",
      "\u001b[32m2023-07-05 14:34:58.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_dump_features\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mend of features dump.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python /usr/src/qlib/scripts/dump_bin.py dump_all --csv_path {CSV_PATH} --qlib_dir {PROVIDER_URI} --date_field_name \"MTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[68325:MainThread](2023-07-05 14:35:10,253) INFO - qlib.Initialization - [config.py:417] - default_conf: client.\n",
      "[68325:MainThread](2023-07-05 14:35:10,431) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[68325:MainThread](2023-07-05 14:35:10,432) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/root/.qlib/qlib_data/bitfinex_data')}\n"
     ]
    }
   ],
   "source": [
    "import qlib\n",
    "from qlib.constant import REG_US\n",
    "\n",
    "MARKET = \"all\"  # instrument\n",
    "BENCHMARK = \"\"  # feature\n",
    "\n",
    "qlib.init(provider_uri=PROVIDER_URI, region=REG_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleNotFoundError. CatBoostModel are skipped. (optional: maybe installing CatBoostModel can fix it.)\n",
      "ModuleNotFoundError. XGBModel is skipped(optional: maybe installing xgboost can fix it).\n",
      "ModuleNotFoundError.  PyTorch models are skipped (optional: maybe installing pytorch can fix it).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[68325:MainThread](2023-07-05 14:35:12,644) INFO - qlib.timer - [log.py:128] - Time cost: 0.211s | Loading data Done\n",
      "[68325:MainThread](2023-07-05 14:35:12,646) INFO - qlib.timer - [log.py:128] - Time cost: 0.001s | DropnaLabel Done\n",
      "[68325:MainThread](2023-07-05 14:35:14,047) INFO - qlib.timer - [log.py:128] - Time cost: 1.401s | CSZScoreNorm Done\n",
      "[68325:MainThread](2023-07-05 14:35:14,048) INFO - qlib.timer - [log.py:128] - Time cost: 1.404s | fit & process data Done\n",
      "[68325:MainThread](2023-07-05 14:35:14,048) INFO - qlib.timer - [log.py:128] - Time cost: 1.615s | Init data Done\n",
      "[68325:MainThread](2023-07-05 14:35:14,051) INFO - qlib.workflow - [exp.py:258] - Experiment 1 starts running ...\n",
      "[68325:MainThread](2023-07-05 14:35:14,102) INFO - qlib.workflow - [recorder.py:341] - Recorder 4530c31bb0564024a101d295c128ba7e starts running under Experiment 1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttrain's l2: 0\tvalid's l2: 0\n",
      "[40]\ttrain's l2: 0\tvalid's l2: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's l2: 0\tvalid's l2: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[68325:MainThread](2023-07-05 14:35:14,511) INFO - qlib.timer - [log.py:128] - Time cost: 0.171s | waiting `async_log` Done\n"
     ]
    }
   ],
   "source": [
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.utils import flatten_dict\n",
    "\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2014-01-01\",\n",
    "    \"end_time\": \"2022-12-31\",\n",
    "    \"fit_start_time\": \"2014-01-01\",\n",
    "    \"fit_end_time\": \"2020-12-31\",\n",
    "    \"instruments\": MARKET,\n",
    "}\n",
    "\n",
    "task = {\n",
    "    \"model\": {\n",
    "        \"class\": \"LGBModel\",\n",
    "        \"module_path\": \"qlib.contrib.model.gbdt\",\n",
    "        \"kwargs\": {\n",
    "            \"loss\": \"mse\",\n",
    "            \"colsample_bytree\": 0.8879,\n",
    "            \"learning_rate\": 0.0421,\n",
    "            \"subsample\": 0.8789,\n",
    "            \"lambda_l1\": 205.6999,\n",
    "            \"lambda_l2\": 580.9768,\n",
    "            \"max_depth\": 8,\n",
    "            \"num_leaves\": 210,\n",
    "            \"num_threads\": 20,\n",
    "        },\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"class\": \"DatasetH\",\n",
    "        \"module_path\": \"qlib.data.dataset\",\n",
    "        \"kwargs\": {\n",
    "            \"handler\": {\n",
    "                \"class\": \"Alpha158\",\n",
    "                \"module_path\": \"qlib.contrib.data.handler\",\n",
    "                \"kwargs\": data_handler_config,\n",
    "            },\n",
    "            \"segments\": {\n",
    "                \"train\": (\"2014-01-01\", \"2020-12-31\"),\n",
    "                \"valid\": (\"2021-01-01\", \"2021-12-31\"),\n",
    "                \"test\": (\"2022-01-01\", \"2022-12-31\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Model initiaiton\n",
    "model = init_instance_by_config(task[\"model\"])\n",
    "dataset = init_instance_by_config(task[\"dataset\"])\n",
    "\n",
    "# Start exp to train model\n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    R.log_params(**flatten_dict(task))\n",
    "    model.fit(dataset)\n",
    "    R.save_objects(trained_model=model)\n",
    "    rid = R.get_recorder().id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
